{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc6c140",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d174e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyMuPDF \n",
    "# !pip install transformers torch\n",
    "# !pip install --upgrade ipywidgets\n",
    "# !pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64d74fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import torch\n",
    "import logging\n",
    "import spacy\n",
    "import os\n",
    "import string\n",
    "import warnings\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, MaxAbsScaler, OneHotEncoder, StandardScaler\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel, TFAutoModel\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b417a19",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab59a12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>text</th>\n",
       "      <th>group</th>\n",
       "      <th>text before lemmatization</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>Provincies willen aan de slag met versoepeling...</td>\n",
       "      <td>provincie willen slag versoepeling stikstofreg...</td>\n",
       "      <td>Bouw &amp; Vastgoed</td>\n",
       "      <td>provincies willen slag versoepeling stikstofre...</td>\n",
       "      <td>[(provincie, NOUN), (willen, VERB), (slag, NOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Het draait allemaal om de drempelwaarde voor e...</td>\n",
       "      <td>draaien allemaal drempelwaran stikstofvergunni...</td>\n",
       "      <td>Bouw &amp; Vastgoed</td>\n",
       "      <td>draait allemaal drempelwaarde stikstofvergunni...</td>\n",
       "      <td>[(draaien, VERB), (allemaal, ADV), (drempelwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Met een hogere drempelwaarde zouden minder ver...</td>\n",
       "      <td>hoog drempelwaard vergunning [NEWLINE] aangevo...</td>\n",
       "      <td>Bouw &amp; Vastgoed</td>\n",
       "      <td>hogere drempelwaarde vergunningen [NEWLINE] aa...</td>\n",
       "      <td>[(hoog, ADJ), (drempelwaard, NOUN), (vergunnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In het hoofdlijnenakkoord hebben de vier coali...</td>\n",
       "      <td>hoofdlijnenakkoord vier coalitiepartij afsprek...</td>\n",
       "      <td>Bouw &amp; Vastgoed</td>\n",
       "      <td>hoofdlijnenakkoord vier coalitiepartijen afges...</td>\n",
       "      <td>[(hoofdlijnenakkoord, PROPN), (vier, NUM), (co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>De ondergrens is al langer onderwerp van discu...</td>\n",
       "      <td>ondergren lang onderwerp discussie huidig Nede...</td>\n",
       "      <td>Bouw &amp; Vastgoed</td>\n",
       "      <td>ondergrens langer onderwerp discussie huidige ...</td>\n",
       "      <td>[(ondergren, VERB), (lang, ADJ), (onderwerp, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <th>2</th>\n",
       "      <td>Telgenkamp vestigt haar hoop voor de korte ter...</td>\n",
       "      <td>telgenkamp vestigen hoop kort termijn twee cru...</td>\n",
       "      <td>Zorg</td>\n",
       "      <td>telgenkamp vestigt hoop korte termijn twee cru...</td>\n",
       "      <td>[(telgenkamp, NOUN), (vestigen, VERB), (hoop, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <th>1</th>\n",
       "      <td>Waarom verzekeraars inkomsten uit zwart werk w...</td>\n",
       "      <td>verzekeraar inkomst zwart werk vergoeden [NEWL...</td>\n",
       "      <td>Zorg</td>\n",
       "      <td>verzekeraars inkomsten zwart werk vergoeden [N...</td>\n",
       "      <td>[(verzekeraar, ADJ), (inkomst, NOUN), (zwart, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">120</th>\n",
       "      <th>1</th>\n",
       "      <td>Verzekeraar wil klant helpen met zorgbemiddeli...</td>\n",
       "      <td>verzekeraar klant helpen zorgbemiddeling [NEWL...</td>\n",
       "      <td>Zorg</td>\n",
       "      <td>verzekeraar klant helpen zorgbemiddeling [NEWL...</td>\n",
       "      <td>[(verzekeraar, ADJ), (klant, NOUN), (helpen, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Verzekeraar wil wachtende patiënt aan snelle z...</td>\n",
       "      <td>verzekeraar wachten patiënt snel zorg helpen [...</td>\n",
       "      <td>Zorg</td>\n",
       "      <td>verzekeraar wachtende patiënt snelle zorg help...</td>\n",
       "      <td>[(verzekeraar, NOUN), (wachten, VERB), (patiën...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zorgbemiddeling is geen wondermiddel, maar kan...</td>\n",
       "      <td>zorgbemiddeling wondermiddel helpen zeggen Haa...</td>\n",
       "      <td>Zorg</td>\n",
       "      <td>zorgbemiddeling wondermiddel helpen zegt haarl...</td>\n",
       "      <td>[(zorgbemiddeling, NOUN), (wondermiddel, NOUN)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             original_text  \\\n",
       "article_id paragraph_id                                                      \n",
       "1          1             Provincies willen aan de slag met versoepeling...   \n",
       "           2             Het draait allemaal om de drempelwaarde voor e...   \n",
       "           3             Met een hogere drempelwaarde zouden minder ver...   \n",
       "           4             In het hoofdlijnenakkoord hebben de vier coali...   \n",
       "           5             De ondergrens is al langer onderwerp van discu...   \n",
       "...                                                                    ...   \n",
       "118        2             Telgenkamp vestigt haar hoop voor de korte ter...   \n",
       "119        1             Waarom verzekeraars inkomsten uit zwart werk w...   \n",
       "120        1             Verzekeraar wil klant helpen met zorgbemiddeli...   \n",
       "           2             Verzekeraar wil wachtende patiënt aan snelle z...   \n",
       "           3             Zorgbemiddeling is geen wondermiddel, maar kan...   \n",
       "\n",
       "                                                                      text  \\\n",
       "article_id paragraph_id                                                      \n",
       "1          1             provincie willen slag versoepeling stikstofreg...   \n",
       "           2             draaien allemaal drempelwaran stikstofvergunni...   \n",
       "           3             hoog drempelwaard vergunning [NEWLINE] aangevo...   \n",
       "           4             hoofdlijnenakkoord vier coalitiepartij afsprek...   \n",
       "           5             ondergren lang onderwerp discussie huidig Nede...   \n",
       "...                                                                    ...   \n",
       "118        2             telgenkamp vestigen hoop kort termijn twee cru...   \n",
       "119        1             verzekeraar inkomst zwart werk vergoeden [NEWL...   \n",
       "120        1             verzekeraar klant helpen zorgbemiddeling [NEWL...   \n",
       "           2             verzekeraar wachten patiënt snel zorg helpen [...   \n",
       "           3             zorgbemiddeling wondermiddel helpen zeggen Haa...   \n",
       "\n",
       "                                   group  \\\n",
       "article_id paragraph_id                    \n",
       "1          1             Bouw & Vastgoed   \n",
       "           2             Bouw & Vastgoed   \n",
       "           3             Bouw & Vastgoed   \n",
       "           4             Bouw & Vastgoed   \n",
       "           5             Bouw & Vastgoed   \n",
       "...                                  ...   \n",
       "118        2                        Zorg   \n",
       "119        1                        Zorg   \n",
       "120        1                        Zorg   \n",
       "           2                        Zorg   \n",
       "           3                        Zorg   \n",
       "\n",
       "                                                 text before lemmatization  \\\n",
       "article_id paragraph_id                                                      \n",
       "1          1             provincies willen slag versoepeling stikstofre...   \n",
       "           2             draait allemaal drempelwaarde stikstofvergunni...   \n",
       "           3             hogere drempelwaarde vergunningen [NEWLINE] aa...   \n",
       "           4             hoofdlijnenakkoord vier coalitiepartijen afges...   \n",
       "           5             ondergrens langer onderwerp discussie huidige ...   \n",
       "...                                                                    ...   \n",
       "118        2             telgenkamp vestigt hoop korte termijn twee cru...   \n",
       "119        1             verzekeraars inkomsten zwart werk vergoeden [N...   \n",
       "120        1             verzekeraar klant helpen zorgbemiddeling [NEWL...   \n",
       "           2             verzekeraar wachtende patiënt snelle zorg help...   \n",
       "           3             zorgbemiddeling wondermiddel helpen zegt haarl...   \n",
       "\n",
       "                                                                  pos_tags  \n",
       "article_id paragraph_id                                                     \n",
       "1          1             [(provincie, NOUN), (willen, VERB), (slag, NOU...  \n",
       "           2             [(draaien, VERB), (allemaal, ADV), (drempelwar...  \n",
       "           3             [(hoog, ADJ), (drempelwaard, NOUN), (vergunnin...  \n",
       "           4             [(hoofdlijnenakkoord, PROPN), (vier, NUM), (co...  \n",
       "           5             [(ondergren, VERB), (lang, ADJ), (onderwerp, N...  \n",
       "...                                                                    ...  \n",
       "118        2             [(telgenkamp, NOUN), (vestigen, VERB), (hoop, ...  \n",
       "119        1             [(verzekeraar, ADJ), (inkomst, NOUN), (zwart, ...  \n",
       "120        1             [(verzekeraar, ADJ), (klant, NOUN), (helpen, V...  \n",
       "           2             [(verzekeraar, NOUN), (wachten, VERB), (patiën...  \n",
       "           3             [(zorgbemiddeling, NOUN), (wondermiddel, NOUN)...  \n",
       "\n",
       "[374 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pre-processed data.csv').set_index(['article_id' , 'paragraph_id'], inplace=False)\n",
    "df['pos_tags'] = df['pos_tags'].apply(ast.literal_eval)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79131840-2c1d-4bf0-bfc6-b7dced4863d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 paragraphs in Bouw & Vastgoed.\n",
      "114 paragraphs in Handel & Industrie.\n",
      "83 paragraphs in Zakelijke Dienstverlening.\n",
      "53 paragraphs in Zorg.\n"
     ]
    }
   ],
   "source": [
    "for group in df['group'].unique():\n",
    "    print(f\"{len(df[df['group'] == group])} paragraphs in {group}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2f1da-ba16-487f-8d96-518aea903d37",
   "metadata": {},
   "source": [
    "# Overarching Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65769f5d-eded-48c7-a5b4-8de793330156",
   "metadata": {},
   "source": [
    "**The function evaluate_model() as described below is an overarching function for finding the model with the highest validation accuracy given the provided parameter values.** <br>\n",
    "\n",
    "Expected parameter values: <br>\n",
    "- **df**: Pandas DataFrame containing the following columns:\n",
    "> **original_text**: Text before any pre-processing steps were taken, $str$ <br>\n",
    "> **text before lemmatization**: Text just before lemmatization has taken place, $str$ <br>\n",
    "> **text**: Text after all pre-processing steps have been completed, $str$ <br>\n",
    "> **pos_tags**: Part-Of-Speech tags, $list$ <br>\n",
    "> **group**: Target variable, $str$ (Converted to numeric in the evaluate_model function) <br>\n",
    "- **test_ratio**: The ratio of the data that is reserved for testing. Any floating point in the inclusive interval [0, 1].\n",
    "> Note that in the case of hold-out cross-validation (which is performed when $k=1$), test_ratio is also used the ratio of training data that is reserved for validation.\n",
    "- **k_values**: List of k values for k-fold cross-validation. Default value: [2, 3, 5, 10, 20]\n",
    "- **model_type**: Selects the type of classifier from amongst the following: [\"svm\", \"naive_bayes\", \"random_forest\"].\n",
    "> If model_type=\"naive_bayes\", a multinomial naive bayes classifier is trained if $pos=$\"none\" and embedding $\\in$ [\"BoW\", \"tf-idf\"]. Otherwise, a Gaussian naive bayes classifier is trained since the resulting word embedding will contain continuous features, which multinomial naive bayes classifiers cannot handle.\n",
    "- **embedding**: Selects the type of word embedding from amongst the following: [\"BoW\", \"tf-idf\", \"BERTje\", \"mBERT\", \"RobBERT\", \"Word2Vec\"].\n",
    "- **pos**: Selects how POS tags are used from amongst the following: [\"none\", \"one-hot\", \"ngram\"].\n",
    "- **ngram_size**: Selects the type of ngrams that are used. Must be an integer, no smaller than 2. Set to 2 by default.\n",
    "> Note that if _pos_$\\neq$\"ngram\", n is not used and the value of ngram_size is irrelevant.\n",
    "- **print_updates**: If set to True, intermediate and final results will be printed in addition to being returned. Default value: True\n",
    "- **show_class_accuracy**: If set to True, the accuracies per class are shown for the final classifier. Default: True\n",
    "- **show_confusion_matrix**: If set to True, the resulting confusion matrix of the final classifier will be shown. Default: True\n",
    "\n",
    "**The parameters below are model-specific and their values are only relevant if the corresponding model type is selected.**\n",
    "\n",
    "- **C_values**: A list containing all values of C to be tested for SVM classifiers. Default value: [0.1, 1, 10]\n",
    "- **kernel_values**: A list containing all kernel types to be tested for SVM classifiers. Default value: ['linear', 'rbf', 'poly']\n",
    "- **max_depth_values**: A list containing all maximum depth values to be tested for Random Forest classifiers. Default value: [5, 10, 15, 20, None]\n",
    "- **alpha_values**: A list containing all $\\alpha$ values to be tested for multinomial naive bayes classifiers. Default value: [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "- **fit_prior_values**: A list containing all prior_values values to be tested for Multinomial Naive Bayes classifiers. Default value: [True, False]\n",
    "- **var_smoothing_values**: A list containing all var_smoothing values to be tested for Gaussian Naive Bayes classifiers. Default value: [$10^{-11}$, $10^{-10}$, $10^{-9}$, $10^{-8}$, $10^{-7}$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20812335-f8b7-4489-9903-e0a0858e7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(df: pd.DataFrame, test_ratio: float = 0.15, k_values: list = [2, 3, 5, 10, 20], \n",
    "                   model_type: str = \"svm\", embedding: str = \"tf-idf\",\n",
    "                   pos: str = \"none\", ngram_size: int = 2, print_updates: bool = True,\n",
    "                   show_class_accuracy: bool = True, show_confusion_matrix: bool = True,\n",
    "                   C_values: list = [0.1, 1, 10], kernel_values: list = ['linear', 'rbf', 'poly'],\n",
    "                   max_depth_values: list = [5, 10, 15, 20, None],\n",
    "                   alpha_values: list = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "                   fit_prior_values: list = [True, False],\n",
    "                   var_smoothing_values: list = [10**-11, 10**-10, 10**-9, 10**-8, 10**-7]):\n",
    "    \"\"\"\n",
    "    Function to extract embeddings (TF-IDF or BERTje), perform classification with SVM hyperparameter tuning, and evaluate using k-fold cross-validation.\n",
    "\n",
    "    For parameters, see the markdown above this cell.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of accuracies for each k and best SVM hyperparameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Raise appropriate error message in case of a faulty parameter value\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(f\"Invalid input data. Please ensure df is a Pandas DataFrame\")\n",
    "    if test_ratio <= 0 or test_ratio >= 1:\n",
    "        raise ValueError(f\"Invalid test_ratio. Choose a value in the exclusive interval (0,1)\")\n",
    "    if not all(isinstance(x, int) and x > 0 for x in k_values):\n",
    "        raise ValueError(f\"Invalid k_values. Please ensure all entries in k_values are positive integers\")\n",
    "    if model_type.lower() not in [\"svm\", \"naive_bayes\", \"random_forest\"]:\n",
    "        raise ValueError(f\"Invalid model_type. Choose from {'SVM', 'Naive_Bayes', 'Random_Forest'}\")\n",
    "    if embedding.lower() not in [\"bow\", \"tf-idf\", \"bertje\", \"mbert\", \"robbert\", \"word2vec\"]:\n",
    "        raise ValueError(f'Invalid embedding. Choose from [\"BoW\", \"tf-idf\", \"BERTje\", \"mBERT\", \"RobBERT\", \"Word2Vec\"]')\n",
    "    if pos not in [\"none\", \"one-hot\", \"ngram\"]:\n",
    "        raise ValueError(f'Invalid pos. Choose from [\"none\", \"one-hot\", \"ngram\"]')\n",
    "    if type(ngram_size) != int or ngram_size < 2:\n",
    "        raise ValueError(f'Invalid ngram_size. Please ensure that ngram_size is an integer, no smaller than 2')\n",
    "    if not type(print_updates) == bool:\n",
    "        raise ValueError(f'Invalid print_updates value. Please ensure this parameter has a boolean value.')\n",
    "    if not all(x > 0 for x in C_values):\n",
    "        raise ValueError(f'Invalid C_values. Please ensure that all entries in C_values lie in the exclusive interval (0, inf)')\n",
    "    if not all(type(x) == str for x in kernel_values):\n",
    "        raise ValueError(f'Invalid kernel_values. Please ensure every entry in kernel_values is a string that represents a kernel type')\n",
    "    if not all((type(x) == int and x > 0) or x == None for x in max_depth_values):\n",
    "        raise ValueError(f'Invalid max_depth_values. Please ensure every entry in max_depth_values is a positive integer or None for no maximum')\n",
    "    if not all((type(x) == int or type(x) == float) and (x > 0) for x in alpha_values):\n",
    "        raise ValueError(f'Invalid alpha_values. Please ensure every entry in alpha_values is numeric and non-negative')\n",
    "    if not all(type(x) == bool for x in fit_prior_values):\n",
    "        raise ValueError(f'Invalid fit_prior_values. Please ensure every entry in fit_prior_values is boolean')\n",
    "    if not all(x >= 0 for x in var_smoothing_values):\n",
    "        raise ValueError(f'Invalid var_smoothing_values. Please ensure every entry in var_smoothing_values is a non-negative number')\n",
    "        \n",
    "\n",
    "    # Convert labels to numeric format\n",
    "    df[\"label\"] = df[\"group\"].astype(\"category\").cat.codes \n",
    "    df_train, df_test = train_test_split(df, test_size=test_ratio, stratify=df[\"label\"], random_state=42)\n",
    "    \n",
    "    # ===========================\n",
    "    # 1. Extract Features (BoW, TF-IDF, BERTje, mBERT, RobBERT or Word2Vec)\n",
    "    # ===========================\n",
    "\n",
    "    if embedding.lower() == \"bow\":\n",
    "        if print_updates:\n",
    "            print(\"\\nUsing Bag of Words (BoW) Embeddings...\")\n",
    "        vectorizer = CountVectorizer(max_features=10_000)\n",
    "        embeddings = vectorizer.fit_transform(df_train[\"text\"])#.toarray()\n",
    "        test_embeddings = vectorizer.transform(df_test[\"text\"])#.toarray()\n",
    "    \n",
    "    elif embedding.lower() == \"tf-idf\":\n",
    "        if print_updates:\n",
    "            print(\"\\nUsing TF-IDF Embeddings...\")\n",
    "        vectorizer = TfidfVectorizer(max_features=10_000)\n",
    "        embeddings = vectorizer.fit_transform(df_train[\"text\"])#.toarray()\n",
    "        test_embeddings = vectorizer.transform(df_test[\"text\"])\n",
    "\n",
    "    elif embedding.lower() in [\"bertje\", \"mbert\", \"robbert\"]:\n",
    "        if embedding.lower() == \"bertje\":\n",
    "            model_name = \"GroNLP/bert-base-dutch-cased\"\n",
    "        elif embedding.lower() == \"mbert\":\n",
    "            model_name = \"bert-base-multilingual-cased\"\n",
    "        elif embedding.lower() == \"robbert\":\n",
    "            model_name = \"pdelobelle/robbert-v2-dutch-base\"\n",
    "\n",
    "        if print_updates:\n",
    "            print(f\"\\nUsing {embedding.upper()} Embeddings ({model_name})...\")\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModel.from_pretrained(model_name)\n",
    "        model.eval()\n",
    "\n",
    "        def get_word_embedding(text):\n",
    "            with torch.no_grad():\n",
    "                tokens = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "                output = model(**tokens)\n",
    "                embeddings = output.last_hidden_state.mean(dim=1)\n",
    "            return embeddings.squeeze().numpy()\n",
    "\n",
    "        if print_updates:\n",
    "            print(f\"\\nCreating {embedding} embedding, this may take a few minutes.\")\n",
    "        embeddings = np.array([get_word_embedding(text) for text in df_train[\"text\"]])\n",
    "        test_embeddings = np.array([get_word_embedding(text) for text in df_test[\"text\"]])\n",
    "\n",
    "    elif embedding.lower() == \"word2vec\":\n",
    "        if print_updates:\n",
    "            print(\"\\nUsing Word2Vec Embeddings...\")\n",
    "\n",
    "        sentences = [text.split() for text in df_train[\"text\"]]\n",
    "        w2v_model = Word2Vec(sentences, vector_size=300, window=5, min_count=2, workers=4)\n",
    "\n",
    "        def get_w2v_embedding(text):\n",
    "            words = text.split()\n",
    "            word_vectors = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "            return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(300)\n",
    "\n",
    "        embeddings = np.array([get_w2v_embedding(text) for text in df_train[\"text\"]])\n",
    "        test_embeddings = np.array([get_w2v_embedding(text) for text in df_test[\"text\"]])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid embedding type. Choose 'tf-idf' 'BERTje', 'mBERT', 'RobBERT' or 'Word2Vec'.\")\n",
    "\n",
    "    # ===========================\n",
    "    # 2. Process POS Tags if Needed\n",
    "    # ===========================\n",
    "\n",
    "    if pos == \"one-hot\":\n",
    "        if print_updates:\n",
    "            print(\"\\nUsing One-Hot Encoding for POS Tags...\")\n",
    "\n",
    "        def pos_to_features(pos_tags):\n",
    "            \"\"\"Convert list of (word, POS) tuples into a dictionary of POS tag counts.\"\"\"\n",
    "            pos_counts = Counter(tag for _, tag in pos_tags)\n",
    "            return dict(pos_counts)\n",
    "\n",
    "        # Convert to list of dictionaries\n",
    "        pos_features = [pos_to_features(tags) for tags in df_train[\"pos_tags\"]]\n",
    "        test_pos_features = [pos_to_features(tags) for tags in df_test[\"pos_tags\"]]\n",
    "    \n",
    "        # Convert list of dictionaries to Pandas DataFrame (fill missing tags with 0)\n",
    "        pos_df = pd.DataFrame(pos_features).fillna(0)\n",
    "        pos_df_test = pd.DataFrame(test_pos_features).fillna(0)\n",
    "\n",
    "        # Ensure that pos_df_test and pos_df_test have the same columns\n",
    "        pos_df_test = pos_df_test.reindex(columns=pos_df.columns, fill_value=0)\n",
    "    \n",
    "        # Create OneHotEncoder and use it on the pos features\n",
    "        encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "        pos_features_encoded = encoder.fit_transform(pos_df)\n",
    "        pos_features_encoded_test = encoder.transform(pos_df_test)\n",
    "    \n",
    "        # Scale the POS features\n",
    "        scaler = StandardScaler()\n",
    "        pos_features_scaled = scaler.fit_transform(pos_features_encoded)\n",
    "        pos_features_scaled_test = scaler.transform(pos_features_encoded_test)\n",
    "\n",
    "        # Ensure embeddings and pos_features_scaled have the same format\n",
    "        if isinstance(embeddings, np.ndarray):  \n",
    "            embeddings = csr_matrix(embeddings)  # Convert dense to sparse\n",
    "        if isinstance(test_embeddings, np.ndarray):  \n",
    "            test_embeddings = csr_matrix(test_embeddings)  # Convert dense to sparse\n",
    "\n",
    "        if not isinstance(pos_features_scaled, csr_matrix):  \n",
    "            pos_features_scaled = csr_matrix(pos_features_scaled)  # Convert dense to sparse\n",
    "        if not isinstance(pos_features_scaled_test, csr_matrix):  \n",
    "            pos_features_scaled_test = csr_matrix(pos_features_scaled_test)  # Convert dense to sparse\n",
    "\n",
    "        # Combine embeddings with POS features\n",
    "        embeddings = hstack([embeddings, pos_features_scaled])\n",
    "        test_embeddings = hstack([test_embeddings, pos_features_scaled_test])\n",
    "\n",
    "    elif pos.lower() == \"ngram\":\n",
    "        if print_updates:\n",
    "            print(f\"\\nUsing N-gram POS Features (n={ngram_size})...\")\n",
    "        \n",
    "        # Function to convert POS tags to n-grams\n",
    "        def pos_to_ngrams(pos_tags, n=2):\n",
    "            \"\"\"Convert a list of POS-tag tuples into n-gram strings.\"\"\"\n",
    "            pos_sequence = [tag for _, tag in pos_tags]  # Extract only POS tags\n",
    "            ngrams = ['_'.join(pos_sequence[i:i+n]) for i in range(len(pos_sequence)-n+1)]\n",
    "            return ' '.join(ngrams)  # Convert to space-separated string for TF-IDF\n",
    "\n",
    "        # Create POS n-grams\n",
    "        pos_ngrams = np.array([pos_to_ngrams(tags, ngram_size) for tags in df_train[\"pos_tags\"]])\n",
    "        pos_ngrams_test = np.array([pos_to_ngrams(tags, ngram_size) for tags in df_test[\"pos_tags\"]])\n",
    "\n",
    "        # Use TF-IDF to extract n-gram features\n",
    "        vectorizer = TfidfVectorizer(max_features=1000)  # Use fewer features since it's for POS\n",
    "        pos_embeddings = vectorizer.fit_transform(pos_ngrams)#.toarray()\n",
    "        pos_embeddings_test = vectorizer.transform(pos_ngrams_test)\n",
    "\n",
    "        # Ensure embeddings and pos_features_scaled have the same format\n",
    "        if isinstance(embeddings, np.ndarray):  \n",
    "            embeddings = csr_matrix(embeddings)  # Convert dense to sparse\n",
    "        if isinstance(test_embeddings, np.ndarray):  \n",
    "            test_embeddings = csr_matrix(test_embeddings)  # Convert dense to sparse\n",
    "\n",
    "        if not isinstance(pos_embeddings, csr_matrix):  \n",
    "            pos_embeddings = csr_matrix(pos_embeddings)  # Convert dense to sparse\n",
    "        if not isinstance(pos_embeddings_test, csr_matrix):  \n",
    "            pos_embeddings_test = csr_matrix(pos_embeddings_test)  # Convert dense to sparse\n",
    "        \n",
    "        # Combine embeddings with POS n-grams features\n",
    "        embeddings = hstack([embeddings, pos_embeddings])\n",
    "        test_embeddings = hstack([test_embeddings, pos_embeddings_test])\n",
    "\n",
    "    elif pos != \"none\":\n",
    "        raise ValueError(\"Invalid POS type. Choose 'none', 'one-hot', or 'ngram'.\")\n",
    "\n",
    "    # ===========================\n",
    "    # 3. Model Evaluation (Holdout or k-Fold) with Hyperparameter Search\n",
    "    # ===========================\n",
    "\n",
    "    # Set initial performance metrics such that they can be updated after a better classifier has been found\n",
    "    best_k = None\n",
    "    best_accuracy = 0\n",
    "    best_params = None\n",
    "    results = {}\n",
    "\n",
    "    # For every value of k, we find the best parameter settings and save them in the results dictionary\n",
    "    for k in k_values:\n",
    "        accuracy_scores = []\n",
    "        best_model_params = {}\n",
    "\n",
    "        if k == 1: # Use regular hold-out cross-validation\n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                embeddings, df_train[\"label\"], test_size=test_ratio, stratify=df_train[\"label\"], random_state=42\n",
    "            )\n",
    "            \n",
    "            if model_type.lower() == \"svm\":\n",
    "                for C in C_values:\n",
    "                    for kernel in kernel_values:\n",
    "                        classifier = SVC(kernel=kernel, C=C)\n",
    "                        classifier.fit(X_train, y_train)\n",
    "                        accuracy = accuracy_score(y_val, classifier.predict(X_val))\n",
    "                        if accuracy > best_accuracy:\n",
    "                            best_accuracy, best_model_params = accuracy, {\"C\": C, \"kernel\": kernel}\n",
    "            \n",
    "            elif model_type.lower() == \"random_forest\":\n",
    "                for max_depth in max_depth_values:\n",
    "                    classifier = RandomForestClassifier(max_depth=max_depth, random_state=42)\n",
    "                    classifier.fit(X_train, y_train)\n",
    "                    accuracy = accuracy_score(y_val, classifier.predict(X_val))\n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_accuracy, best_model_params = accuracy, {\"max_depth\": max_depth}\n",
    "            \n",
    "            elif model_type.lower() == \"naive_bayes\":\n",
    "                if pos == \"none\" and embedding.lower() in [\"bow\", \"tf-idf\"]: # In this case all features are discrete, so we can use MultinomialNB\n",
    "                    for alpha in alpha_values:\n",
    "                        for fit_prior in fit_prior_values:\n",
    "                            classifier = MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
    "                            classifier.fit(X_train, y_train)\n",
    "                            accuracy = accuracy_score(y_val, classifier.predict(X_val))\n",
    "                            if accuracy > best_accuracy:\n",
    "                                best_accuracy, best_model_params = accuracy, {\"alpha\": alpha, \"fit_prior\": fit_prior}\n",
    "                else: # In this case, there are continuous features, so we use GaussianNB\n",
    "                    for var_smoothing in var_smoothing_values:\n",
    "                        classifier = GaussianNB(var_smoothing=var_smoothing)\n",
    "                        classifier.fit(X_train.toarray(), y_train)  # Convert sparse to dense for GaussianNB\n",
    "                        accuracy = accuracy_score(y_val, classifier.predict(X_val.toarray()))\n",
    "                        if accuracy > best_accuracy:\n",
    "                            best_accuracy, best_model_params = accuracy, {\"var_smoothing\": var_smoothing}\n",
    "\n",
    "            else:\n",
    "                raise ValueError('Invalid model_type. Choose \"svm\", \"random_forest\" or \"naive_bayes\".')\n",
    "\n",
    "            accuracy_scores.append(best_accuracy)\n",
    "            \n",
    "        else:  # Use stratified k-fold cross-validation\n",
    "            kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "            for train_index, val_index in kf.split(embeddings, df_train[\"label\"]):\n",
    "                X_train, X_val = embeddings[train_index], embeddings[val_index]\n",
    "                y_train, y_val = df_train[\"label\"].iloc[train_index].values, df_train[\"label\"].iloc[val_index].values\n",
    "                \n",
    "                best_fold_accuracy = 0\n",
    "                \n",
    "                if model_type == \"svm\":\n",
    "                    for C in C_values:\n",
    "                        for kernel in kernel_values:\n",
    "                            classifier = SVC(kernel=kernel, C=C)\n",
    "                            classifier.fit(X_train, y_train)\n",
    "                            accuracy = accuracy_score(y_val, classifier.predict(X_val))\n",
    "                            if accuracy > best_fold_accuracy:\n",
    "                                best_fold_accuracy, best_model_params = accuracy, {\"C\": C, \"kernel\": kernel}\n",
    "                \n",
    "                elif model_type == \"random_forest\":\n",
    "                    for max_depth in max_depth_values:\n",
    "                        classifier = RandomForestClassifier(max_depth=max_depth, random_state=42)\n",
    "                        classifier.fit(X_train, y_train)\n",
    "                        accuracy = accuracy_score(y_val, classifier.predict(X_val))\n",
    "                        if accuracy > best_fold_accuracy:\n",
    "                            best_fold_accuracy, best_model_params = accuracy, {\"max_depth\": max_depth}\n",
    "                \n",
    "                elif model_type == \"naive_bayes\":\n",
    "                    if pos == \"none\" and embedding.lower() in [\"bow\", \"tf-idf\"]:\n",
    "                        for alpha in alpha_values:\n",
    "                            for fit_prior in fit_prior_values:\n",
    "                                classifier = MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
    "                                classifier.fit(X_train, y_train)\n",
    "                                accuracy = accuracy_score(y_val, classifier.predict(X_val))\n",
    "                                if accuracy > best_fold_accuracy:\n",
    "                                    best_fold_accuracy, best_model_params = accuracy, {\"alpha\": alpha, \"fit_prior\": fit_prior}\n",
    "                    else:\n",
    "                        for var_smoothing in var_smoothing_values:\n",
    "                            classifier = GaussianNB(var_smoothing=var_smoothing)\n",
    "                            classifier.fit(X_train.toarray(), y_train)\n",
    "                            accuracy = accuracy_score(y_val, classifier.predict(X_val.toarray()))\n",
    "                            if accuracy > best_fold_accuracy:\n",
    "                                best_fold_accuracy, best_model_params = accuracy, {\"var_smoothing\": var_smoothing}\n",
    "                                \n",
    "                else:\n",
    "                    raise ValueError('Invalid model_type. Choose \"svm\", \"random_forest\" or \"naive_bayes\".')\n",
    "                \n",
    "                accuracy_scores.append(best_fold_accuracy)\n",
    "        \n",
    "        results[k] = {\"accuracy\": np.mean(accuracy_scores), \"best_params\": best_model_params}\n",
    "        \n",
    "        if print_updates:\n",
    "            print(f\"Best {model_type} Params for k={k}: {results[k]['best_params']}, Mean Validation Accuracy: {results[k]['accuracy']:.4f}\")\n",
    "\n",
    "        print(results[k]['accuracy'], best_accuracy)\n",
    "        if results[k][\"accuracy\"] > best_accuracy:\n",
    "            best_k = k\n",
    "            best_accuracy = results[k][\"accuracy\"]\n",
    "            best_params = best_model_params\n",
    "            print('A best model is found') # Remove me once you're done testing\n",
    "            best_model = classifier\n",
    "\n",
    "    # Evaluate best model on test set\n",
    "    if not isinstance(test_embeddings, np.ndarray):\n",
    "        test_accuracy = accuracy_score(df_test[\"label\"], best_model.predict(test_embeddings.toarray()))\n",
    "    else:\n",
    "        test_accuracy = accuracy_score(df_test[\"label\"], best_model.predict(test_embeddings))\n",
    "    if print_updates:\n",
    "        print(f\"\\nBest model found: \\nModel={model_type}, \\nParameter values: {results[best_k]['best_params']}, \\nValidation Accuracy: {results[best_k]['accuracy']}\")\n",
    "        print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    if show_class_accuracy:\n",
    "        y_test = df_test[\"label\"]\n",
    "        \n",
    "        if not isinstance(test_embeddings, np.ndarray):\n",
    "            y_pred = best_model.predict(test_embeddings.toarray())\n",
    "        else:\n",
    "            y_pred = best_model.predict(test_embeddings)\n",
    "            \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Class names (assuming they are in the same order as in y_train or y_test)\n",
    "        class_names = np.unique(y_test)  # This will give you the unique class labels\n",
    "        \n",
    "        # Calculate per-class accuracy: TP / (TP + FN)\n",
    "        class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
    "        \n",
    "        # Print the accuracy for each class along with its name\n",
    "        for i, acc in enumerate(class_accuracies):\n",
    "            print(f\"Class '{class_names[i]}' Accuracy: {acc:.4f}\")\n",
    "\n",
    "    if show_confusion_matrix:\n",
    "        y_test = df_test[\"label\"]\n",
    "        \n",
    "        if not isinstance(test_embeddings, np.ndarray):\n",
    "            y_pred = best_model.predict(test_embeddings.toarray())\n",
    "        else:\n",
    "            y_pred = best_model.predict(test_embeddings)\n",
    "            \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        class_mapping = {0: 'Bouw & Vastgoed', 1: 'Handel & Industrie', 2: 'Zakelijke Dienstverlening', 3: 'Zorg'}\n",
    "        class_names = [class_mapping[i] for i in np.unique(y_test)]\n",
    "        \n",
    "        # Plotting the confusion matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, cbar=True)\n",
    "        \n",
    "        # Label the axes\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title('Confusion Matrix')\n",
    "        \n",
    "        # Display the plot\n",
    "        plt.show()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c179dff8-567d-4823-acea-631d80658028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Bag of Words (BoW) Embeddings...\n",
      "\n",
      "Using N-gram POS Features (n=2)...\n",
      "Best random_forest Params for k=1: {'max_depth': 5}, Mean Validation Accuracy: 0.6042\n",
      "0.6041666666666666 0.6041666666666666\n",
      "Best random_forest Params for k=2: {'max_depth': 20}, Mean Validation Accuracy: 0.4889\n",
      "0.4889340020698989 0.6041666666666666\n",
      "Best random_forest Params for k=3: {'max_depth': 5}, Mean Validation Accuracy: 0.5078\n",
      "0.5077867625037437 0.6041666666666666\n",
      "Best random_forest Params for k=5: {'max_depth': 15}, Mean Validation Accuracy: 0.5426\n",
      "0.5426091269841271 0.6041666666666666\n",
      "Best random_forest Params for k=10: {'max_depth': 20}, Mean Validation Accuracy: 0.5424\n",
      "0.5424395161290324 0.6041666666666666\n",
      "Best random_forest Params for k=20: {'max_depth': 5}, Mean Validation Accuracy: 0.5644\n",
      "0.564375 0.6041666666666666\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'best_model' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m               \u001b[49m\u001b[43mtest_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m               \u001b[49m\u001b[43mk_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m               \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBoW\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrandom_forest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43mpos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mngram\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m               \u001b[49m\u001b[43mprint_updates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m               \u001b[49m\u001b[43mshow_class_accuracy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m               \u001b[49m\u001b[43mshow_confusion_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 325\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(df, test_ratio, k_values, model_type, embedding, pos, ngram_size, print_updates, show_class_accuracy, show_confusion_matrix, C_values, kernel_values, max_depth_values, alpha_values, fit_prior_values, var_smoothing_values)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# Evaluate best model on test set\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(test_embeddings, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m--> 325\u001b[0m     test_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[43mbest_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(test_embeddings\u001b[38;5;241m.\u001b[39mtoarray()))\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    327\u001b[0m     test_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m], best_model\u001b[38;5;241m.\u001b[39mpredict(test_embeddings))\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'best_model' referenced before assignment"
     ]
    }
   ],
   "source": [
    "evaluate_model(df, \n",
    "               test_ratio=0.15, \n",
    "               k_values=[1, 2, 3, 5, 10, 20],\n",
    "               embedding='BoW', \n",
    "               model_type=\"random_forest\",\n",
    "               pos='ngram', \n",
    "               ngram_size=2,\n",
    "               print_updates=True,\n",
    "               show_class_accuracy=True, \n",
    "               show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f1cb8e-3aea-49ae-8f44-f14583996f4b",
   "metadata": {},
   "source": [
    "# Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf1789-14a2-4917-b1fa-f3abf782beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(df, test_ratio = 0.15, k_values = [2, 3, 5], \n",
    "                   embedding = \"tf-idf\", model_type = \"random_forest\",\n",
    "                   C_values = [0.1, 1, 10], kernel_values = ['linear', 'rbf', 'poly'],\n",
    "                   max_depth_values = [5, 10, 15, 20, None],\n",
    "                   alpha_values = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "                   fit_prior_values = [True, False],\n",
    "                   var_smoothing_values = [10**-11, 10**-10, 10**-9, 10**-8, 10**-7],\n",
    "                   pos = \"none\", ngram_size = 2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e5d384-a5c4-4c31-b78d-02cd6e26505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(df, test_ratio = 0.15, k_values = [2, 3, 5], \n",
    "                   embedding = \"BERTje\", model_type = \"random_forest\",\n",
    "                   C_values = [0.1, 1, 10], kernel_values = ['linear', 'rbf', 'poly'],\n",
    "                   max_depth_values = [5, 10, 15, 20, None],\n",
    "                   alpha_values = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "                   fit_prior_values = [True, False],\n",
    "                   var_smoothing_values = [10**-11, 10**-10, 10**-9, 10**-8, 10**-7],\n",
    "                   pos = \"none\", ngram_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b3d6c4-8346-44e6-ac90-fe229c91e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(df, test_ratio = 0.15, k_values = [2, 3, 5], \n",
    "                   embedding = \"tf-idf\", model_type = \"random_forest\",\n",
    "                   C_values = [0.1, 1, 10], kernel_values = ['linear', 'rbf', 'poly'],\n",
    "                   max_depth_values = [5, 10, 15, 20, None],\n",
    "                   alpha_values = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "                   fit_prior_values = [True, False],\n",
    "                   var_smoothing_values = [10**-11, 10**-10, 10**-9, 10**-8, 10**-7],\n",
    "                   pos = \"one-hot\", ngram_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e439779-31d0-4d7f-a242-21bc47ebfcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(df, test_ratio = 0.15, k_values = [2, 3, 5], \n",
    "                   embedding = \"mbert\", model_type = \"random_forest\",\n",
    "                   C_values = [0.1, 1, 10], kernel_values = ['linear', 'rbf', 'poly'],\n",
    "                   max_depth_values = [5, 10, 15, 20, None],\n",
    "                   alpha_values = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "                   fit_prior_values = [True, False],\n",
    "                   var_smoothing_values = [10**-11, 10**-10, 10**-9, 10**-8, 10**-7],\n",
    "                   pos = \"ngram\", ngram_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593ea37e-589b-4bf3-8bcc-4de3550f0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(df, test_ratio = 0.15, k_values = [2, 3, 5], \n",
    "                   embedding = \"BERTje\", model_type = \"svm\",\n",
    "                   C_values = [0.1, 1, 10], kernel_values = ['linear', 'rbf', 'poly'],\n",
    "                   max_depth_values = [5, 10, 15, 20, None],\n",
    "                   alpha_values = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "                   fit_prior_values = [True, False],\n",
    "                   var_smoothing_values = [10**-11, 10**-10, 10**-9, 10**-8, 10**-7],\n",
    "                   pos = \"none\", ngram_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f5f14-abea-4e15-9690-703a63f98f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(df, test_ratio = 0.15, k_values = [2, 3, 5], \n",
    "                   embedding = \"BoW\", model_type = \"svm\",\n",
    "                   C_values = [0.1, 1, 10], kernel_values = ['linear', 'rbf', 'poly'],\n",
    "                   max_depth_values = [5, 10, 15, 20, None],\n",
    "                   alpha_values = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "                   fit_prior_values = [True, False],\n",
    "                   var_smoothing_values = [10**-11, 10**-10, 10**-9, 10**-8, 10**-7],\n",
    "                   pos = \"one-hot\", ngram_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb0f54-7aca-41bd-ad44-c2e5c116d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(df, test_ratio = 0.15, k_values = [2, 3, 5], \n",
    "                   embedding = \"robBERT\", model_type = \"svm\",\n",
    "                   C_values = [0.1, 1, 10], kernel_values = ['linear', 'rbf', 'poly'],\n",
    "                   max_depth_values = [5, 10, 15, 20, None],\n",
    "                   alpha_values = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "                   fit_prior_values = [True, False],\n",
    "                   var_smoothing_values = [10**-11, 10**-10, 10**-9, 10**-8, 10**-7],\n",
    "                   pos = \"ngram\", ngram_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2576a7-c632-4f37-b94d-5f0c0f4f1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(df, test_ratio = 0.15, k_values = [2, 3, 5], \n",
    "                   embedding = \"tf-idf\", model_type = \"naive_bayes\",\n",
    "                   C_values = [0.1, 1, 10], kernel_values = ['linear', 'rbf', 'poly'],\n",
    "                   max_depth_values = [5, 10, 15, 20, None],\n",
    "                   alpha_values = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "                   fit_prior_values = [True, False],\n",
    "                   var_smoothing_values = [10**-11, 10**-10, 10**-9, 10**-8, 10**-7],\n",
    "                   pos = \"none\", ngram_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa4f8c-a329-475f-9091-1ed0077ef729",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(df, test_ratio = 0.15, k_values = [2, 3, 5], \n",
    "                   embedding = \"tf-idf\", model_type = \"naive_bayes\",\n",
    "                   C_values = [0.1, 1, 10], kernel_values = ['linear', 'rbf', 'poly'],\n",
    "                   max_depth_values = [5, 10, 15, 20, None],\n",
    "                   alpha_values = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "                   fit_prior_values = [True, False],\n",
    "                   var_smoothing_values = [10**-11, 10**-10, 10**-9, 10**-8, 10**-7],\n",
    "                   pos = \"none\", ngram_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73858ac7-b747-47f0-a9f8-a5e447086153",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(df, test_ratio = 0.15, k_values = [2, 3, 5], \n",
    "                   embedding = \"BoW\", model_type = \"naive_bayes\",\n",
    "                   C_values = [0.1, 1, 10], kernel_values = ['linear', 'rbf', 'poly'],\n",
    "                   max_depth_values = [5, 10, 15, 20, None],\n",
    "                   alpha_values = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "                   fit_prior_values = [True, False],\n",
    "                   var_smoothing_values = [10**-11, 10**-10, 10**-9, 10**-8, 10**-7],\n",
    "                   pos = \"ngram\", ngram_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a52df0-8bbf-496d-ae72-22c8305b8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do:\n",
    "\n",
    "# -Add some print statements to show the model chosen en parameters, especially for Gaussian- of Multinomial Naive Bayes\n",
    "# -Print update of best model after every k\n",
    "# -Clean Code and add/remove/update comments where needed\n",
    "# -Return actual model and validation accuracy such that we can visualize the results in confusion matrices\n",
    "# -If 2 classes too close in likelihood or no class likelihood exceeds threshold, then say class 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c0e4d6-b432-474b-9dc6-c849606fb3e4",
   "metadata": {},
   "source": [
    "# Finding the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f21a1a-684a-4858-bffc-635d70fde24e",
   "metadata": {},
   "source": [
    "Our goal is to find the classifier with the highest validation accuracy for each model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75715a-e332-4874-b594-16a7d501c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore all warnings since they cause problems for te progress bars\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ecc2d9-6a87-42c4-bb73-ba92087537ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "counter = 0\n",
    "n_values = [2, 3, 5]\n",
    "\n",
    "# Total iterations to track progress\n",
    "total_combinations = len([\"BoW\", \"tf-idf\", \"BERTje\", \"mBERT\", \"RobBERT\", \"Word2Vec\"]) * len([\"none\", \"one-hot\"] + 3 * [\"ngram\"])\n",
    "\n",
    "# Initialize tracking variables\n",
    "best_overall_model = None\n",
    "best_overall_accuracy = float('-inf')\n",
    "best_overall_params = None\n",
    "\n",
    "# Create tqdm progress bar\n",
    "with tqdm(total=total_combinations, desc=\"Progress\", unit=\"iteration\") as pbar:\n",
    "    for embedding in [\"BoW\", \"tf-idf\", \"BERTje\", \"mBERT\", \"RobBERT\", \"Word2Vec\"]:\n",
    "        for pos in [\"none\", \"one-hot\"] + 3 * [\"ngram\"]:\n",
    "            \n",
    "            n = 2  # Default value in case pos != \"ngram\"\n",
    "            if pos == \"ngram\":\n",
    "                n = n_values[counter % 3]\n",
    "                counter += 1\n",
    "            \n",
    "            results = evaluate_model(df, \n",
    "                                     test_ratio=0.15, \n",
    "                                     k_values=[1, 2, 3, 5, 10, 20],\n",
    "                                     embedding=embedding, \n",
    "                                     model_type=\"random_forest\",\n",
    "                                     pos=pos, \n",
    "                                     ngram_size=n,\n",
    "                                     print_updates=False,\n",
    "                                     show_class_accuracy=False, \n",
    "                                     show_confusion_matrix=False)\n",
    "\n",
    "            # Find the best model in this iteration\n",
    "            global_best_model = max(results.items(), key=lambda x: x[1]['accuracy'])\n",
    "            global_best_model_key = global_best_model[0]\n",
    "            best_accuracy = global_best_model[1]['accuracy']\n",
    "            best_params = global_best_model[1]['best_params']\n",
    "\n",
    "            # Update global best if the current model is better\n",
    "            if best_accuracy > best_overall_accuracy:\n",
    "                print(f\"Best validaton accuracy increased from {best_overall_accuracy} to {best_accuracy} with params {embedding}, {pos}, {best_params}.\\n\")\n",
    "                best_overall_accuracy = best_accuracy\n",
    "                best_overall_model = (embedding, pos, global_best_model_key)\n",
    "                best_overall_params = best_params\n",
    "\n",
    "            # Update the progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "# Print the overall best model after all iterations\n",
    "print(f\"Best overall model: {best_overall_model}\")\n",
    "print(f\"Best overall accuracy: {best_overall_accuracy}\")\n",
    "print(f\"Best overall parameters: {best_overall_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a5987-e39d-4f54-97e3-5d9a824a7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "counter = 0\n",
    "n_values = [2, 3, 5]\n",
    "\n",
    "# Total iterations to track progress\n",
    "total_combinations = len([\"BoW\", \"tf-idf\", \"BERTje\", \"mBERT\", \"RobBERT\", \"Word2Vec\"]) * len([\"none\", \"one-hot\"] + 3 * [\"ngram\"])\n",
    "\n",
    "# Initialize tracking variables\n",
    "best_overall_model = None\n",
    "best_overall_accuracy = float('-inf')\n",
    "best_overall_params = None\n",
    "\n",
    "# Create tqdm progress bar\n",
    "with tqdm(total=total_combinations, desc=\"Progress\", unit=\"iteration\") as pbar:\n",
    "    for embedding in [\"BoW\", \"tf-idf\", \"BERTje\", \"mBERT\", \"RobBERT\", \"Word2Vec\"]:\n",
    "        for pos in [\"none\", \"one-hot\"] + 3 * [\"ngram\"]:\n",
    "            \n",
    "            n = 2  # Default value in case pos != \"ngram\"\n",
    "            if pos == \"ngram\":\n",
    "                n = n_values[counter % 3]\n",
    "                counter += 1\n",
    "            \n",
    "            results = evaluate_model(df, \n",
    "                                     test_ratio=0.15, \n",
    "                                     k_values=[1, 2, 3, 5, 10, 20],\n",
    "                                     embedding=embedding, \n",
    "                                     model_type=\"svm\",\n",
    "                                     pos=pos, \n",
    "                                     ngram_size=n,\n",
    "                                     print_updates=False,\n",
    "                                     show_class_accuracy=False, \n",
    "                                     show_confusion_matrix=False)\n",
    "\n",
    "            # Find the best model in this iteration\n",
    "            global_best_model = max(results.items(), key=lambda x: x[1]['accuracy'])\n",
    "            global_best_model_key = global_best_model[0]\n",
    "            best_accuracy = global_best_model[1]['accuracy']\n",
    "            best_params = global_best_model[1]['best_params']\n",
    "\n",
    "            # Update global best if the current model is better\n",
    "            if best_accuracy > best_overall_accuracy:\n",
    "                print(f\"Best validaton accuracy increased from {best_overall_accuracy} to {best_accuracy} with params {embedding}, {pos}, {best_params}.\\n\")\n",
    "                best_overall_accuracy = best_accuracy\n",
    "                best_overall_model = (embedding, pos, global_best_model_key)\n",
    "                best_overall_params = best_params\n",
    "\n",
    "            # Update the progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "# Print the overall best model after all iterations\n",
    "print(f\"Best overall model: {best_overall_model}\")\n",
    "print(f\"Best overall accuracy: {best_overall_accuracy}\")\n",
    "print(f\"Best overall parameters: {best_overall_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8429373c-08d5-434c-987e-2ad413c33261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "counter = 0\n",
    "n_values = [2, 3, 5]\n",
    "\n",
    "# Total iterations to track progress\n",
    "total_combinations = len([\"BoW\", \"tf-idf\", \"BERTje\", \"mBERT\", \"RobBERT\", \"Word2Vec\"]) * len([\"none\", \"one-hot\"] + 3 * [\"ngram\"])\n",
    "\n",
    "# Initialize tracking variables\n",
    "best_overall_model = None\n",
    "best_overall_accuracy = float('-inf')\n",
    "best_overall_params = None\n",
    "\n",
    "# Create tqdm progress bar\n",
    "with tqdm(total=total_combinations, desc=\"Progress\", unit=\"iteration\") as pbar:\n",
    "    for embedding in [\"BoW\", \"tf-idf\", \"BERTje\", \"mBERT\", \"RobBERT\", \"Word2Vec\"]:\n",
    "        for pos in [\"none\", \"one-hot\"] + 3 * [\"ngram\"]:\n",
    "            \n",
    "            n = 2  # Default value in case pos != \"ngram\"\n",
    "            if pos == \"ngram\":\n",
    "                n = n_values[counter % 3]\n",
    "                counter += 1\n",
    "            \n",
    "            results = evaluate_model(df, \n",
    "                                     test_ratio=0.15, \n",
    "                                     k_values=[1, 2, 3, 5, 10, 20],\n",
    "                                     embedding=embedding, \n",
    "                                     model_type=\"naive_bayes\",\n",
    "                                     pos=pos, \n",
    "                                     ngram_size=n,\n",
    "                                     print_updates=False,\n",
    "                                     show_class_accuracy=False, \n",
    "                                     show_confusion_matrix=False)\n",
    "\n",
    "            # Find the best model in this iteration\n",
    "            global_best_model = max(results.items(), key=lambda x: x[1]['accuracy'])\n",
    "            global_best_model_key = global_best_model[0]\n",
    "            best_accuracy = global_best_model[1]['accuracy']\n",
    "            best_params = global_best_model[1]['best_params']\n",
    "\n",
    "            # Update global best if the current model is better\n",
    "            if best_accuracy > best_overall_accuracy:\n",
    "                print(f\"Best validaton accuracy increased from {best_overall_accuracy} to {best_accuracy} with params {embedding}, {pos}, {best_params}.\\n\")\n",
    "                best_overall_accuracy = best_accuracy\n",
    "                best_overall_model = (embedding, pos, global_best_model_key)\n",
    "                best_overall_params = best_params\n",
    "\n",
    "            # Update the progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "# Print the overall best model after all iterations\n",
    "print(f\"Best overall model: {best_overall_model}\")\n",
    "print(f\"Best overall accuracy: {best_overall_accuracy}\")\n",
    "print(f\"Best overall parameters: {best_overall_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1509cbb-6c44-4a91-9c45-89b8dece4111",
   "metadata": {},
   "source": [
    "# Small test on 2 articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e4b7df-c4f5-4e99-8d30-48697de67424",
   "metadata": {},
   "source": [
    "This section aims to test the obtained classifier for 2 articles. To achieve this, we first load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db744975-3d00-4fba-a286-af6522be0aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "directory = 'small experiment for presentation'\n",
    "df_experiment = pd.DataFrame(columns=['article_id' , 'paragraph_id', 'text', 'group', 'publication_date'])\n",
    "\n",
    "print('Please ensure that only pdf files of articles are present in the subfolders of the specified directory')\n",
    "article_nr = 1\n",
    "for folder in os.listdir(directory):\n",
    "    folder_size = len(os.listdir(directory + \"\\\\\" + folder))\n",
    "    print(f'{folder_size} article(s) detected in {folder} folder')\n",
    "    \n",
    "    for article in os.listdir(directory + '\\\\' + folder):\n",
    "        text = extract_text_from_pdf(directory + '\\\\' + folder + '\\\\' + article)\n",
    "        date = article.split(' ')[-1].split('.')[0] #Remove the article number and \".pdf\" to obtain the publication date\n",
    "        \n",
    "        paragraphs = [para.strip() for para in text.split(\"\\n \\n\") if para.strip()]\n",
    "        para_nr = 1\n",
    "        for para in paragraphs:\n",
    "            df_temp = pd.DataFrame([[article_nr, para_nr, para, folder, date]], \n",
    "                                   columns=['article_id' , 'paragraph_id', 'text', 'group', 'publication_date'])\n",
    "            df_experiment = pd.concat([df_experiment, df_temp])\n",
    "            para_nr += 1\n",
    "        article_nr += 1\n",
    "        \n",
    "df_experiment.set_index(['article_id' , 'paragraph_id'], inplace=True)\n",
    "df_experiment['publication_date'] = pd.to_datetime(df_experiment['publication_date'], format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667ff88-4d09-49bf-80f2-8f5c40293147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57574524-fe00-40e4-bd0a-cac9155457bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 'nl_core_news_sm' model\n",
    "nlp = spacy.load('nl_core_news_sm')\n",
    "\n",
    "# Add [NEWLINE] as a single token so that it is not split into 3 seperate tokens\n",
    "special_cases = {\"[NEWLINE]\": [{\"ORTH\": \"[NEWLINE]\"}]}\n",
    "nlp.tokenizer.add_special_case(\"[NEWLINE]\", [{\"ORTH\": \"[NEWLINE]\"}])\n",
    "\n",
    "df_experiment_clean = df_experiment.copy()\n",
    "df_experiment_clean['original_text'] = df_experiment_clean['text'].copy()\n",
    "df_experiment_clean = df_clean[['original_text', 'text', 'group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32b23e3-013b-41af-9491-87f016a760b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_normalization(text):\n",
    "    \"\"\"Returns string of input containing only lowercase letters apart from [NEWLINE], which replaces \\n\"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' [NEWLINE] ')\n",
    "    while text != text.replace('  ', ' '):\n",
    "        text = text.replace('  ', ' ')\n",
    "    return text\n",
    "\n",
    "df_experiment_clean['text'] = df_experiment_clean['text'].apply(case_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab99f3c-7e25-449b-865c-b2761c1952f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"Returns the input text with all punctuation removed\"\"\"\n",
    "    \n",
    "    text = text.translate(text.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = text.replace(\"NEWLINE\", \"[NEWLINE]\")\n",
    "    return text\n",
    "\n",
    "df_experiment_clean['text'] = df_experiment_clean['text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2abb0bc-3f3f-4035-a94d-1553ae1159a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"Returns string of input text with stopwords removed\"\"\"\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    filtered_words = [token.text for token in doc if not token.is_stop]\n",
    "    text = \" \".join(filtered_words)\n",
    "    return text\n",
    "    \n",
    "    \n",
    "# nlp = spacy.load(\"nl_core_news_sm\")\n",
    "df_experiment_clean['text'] = df_experiment_clean['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f233960-d718-445f-8458-5fcf6fad811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(df, text_column=\"text\", output_column=\"text\"):\n",
    "    \"\"\"Lemmatizes the text in a specified column of a DataFrame and adds the results to a new column.\"\"\"\n",
    "    \n",
    "    # Ensure the input column exists in the DataFrame\n",
    "    if text_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{text_column}' does not exist in the DataFrame.\")\n",
    "        \n",
    "    # Apply SpaCy processing and lemmatization\n",
    "    df[output_column] = df[text_column].apply(\n",
    "        lambda text: \" \".join([token.lemma_ for token in nlp(text) if not token.is_punct and not token.is_space]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_experiment_clean['text before lemmatization'] = df_experiment_clean['text'].copy()\n",
    "df_experiment_clean = lemmatization(df_experiment_clean, text_column=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463024d-b119-4d23-b838-bd823614efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def POS_tagging(text):\n",
    "    \"\"\"Returns a list of (token, POS tag) tuples for the input text\"\"\"\n",
    "    doc = nlp(text)\n",
    "    pos_tags = [(token.text, token.pos_) for token in doc]pospospospos\n",
    "    return pos_tags\n",
    "\n",
    "df_experiment_clean['pos_tags'] = df_experiment_clean['text'].apply(POS_tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53961193-226e-4960-b8e7-afd6b8f5e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiment_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb19045b-0e78-4793-a8fb-bd32a1507078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d26107c-ccd9-496b-809a-fcafbc394014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8eb47-f044-4093-b7f4-6ca26748dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process these rows, make the embedding (using the settings of the best model) and test it on the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0fcedc-507d-49cb-adec-1955dd2ed15d",
   "metadata": {},
   "source": [
    "# once this is done, select model based on highest non-class 5 (uncertain class) validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860d50c-0fe2-4359-a42c-4aeb147265bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de909a14-8ea1-4101-bd5f-9db0b28d5176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
